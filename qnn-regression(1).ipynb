{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11860904,"sourceType":"datasetVersion","datasetId":7453101}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Load data","metadata":{"id":"2awyvLCkqQYK"}},{"cell_type":"code","source":"! pip install pennylane\n! pip install torch\n! pip install torch_geometric\n! pip install tensorflow\n! pip install torchsummary\n","metadata":{"id":"8DkYoMZFw4hb","colab":{"base_uri":"https://localhost:8080/"},"outputId":"8e7cd7b4-6484-4091-eb88-cefe4bab4bb0","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:50:38.867510Z","iopub.execute_input":"2025-05-18T16:50:38.867794Z","iopub.status.idle":"2025-05-18T16:52:13.508917Z","shell.execute_reply.started":"2025-05-18T16:50:38.867770Z","shell.execute_reply":"2025-05-18T16:52:13.508094Z"}},"outputs":[{"name":"stdout","text":"Collecting pennylane\n  Downloading PennyLane-0.41.1-py3-none-any.whl.metadata (10 kB)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.26.4)\nRequirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.15.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from pennylane) (3.4.2)\nCollecting rustworkx>=0.14.0 (from pennylane)\n  Downloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\nRequirement already satisfied: autograd in /usr/local/lib/python3.11/dist-packages (from pennylane) (1.7.0)\nCollecting tomlkit (from pennylane)\n  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\nCollecting appdirs (from pennylane)\n  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\nCollecting autoray>=0.6.11 (from pennylane)\n  Downloading autoray-0.7.1-py3-none-any.whl.metadata (5.8 kB)\nRequirement already satisfied: cachetools in /usr/local/lib/python3.11/dist-packages (from pennylane) (5.5.2)\nCollecting pennylane-lightning>=0.41 (from pennylane)\n  Downloading pennylane_lightning-0.41.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (12 kB)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pennylane) (2.32.3)\nRequirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from pennylane) (4.13.2)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from pennylane) (25.0)\nCollecting diastatic-malt (from pennylane)\n  Downloading diastatic_malt-2.15.2-py3-none-any.whl.metadata (2.6 kB)\nCollecting scipy-openblas32>=0.3.26 (from pennylane-lightning>=0.41->pennylane)\n  Downloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (56 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->pennylane) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->pennylane) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->pennylane) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->pennylane) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->pennylane) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->pennylane) (2.4.1)\nRequirement already satisfied: astunparse in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (1.6.3)\nRequirement already satisfied: gast in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (0.6.0)\nRequirement already satisfied: termcolor in /usr/local/lib/python3.11/dist-packages (from diastatic-malt->pennylane) (3.0.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pennylane) (2025.4.26)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (0.45.1)\nRequirement already satisfied: six<2.0,>=1.6.1 in /usr/local/lib/python3.11/dist-packages (from astunparse->diastatic-malt->pennylane) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pennylane) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pennylane) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->pennylane) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->pennylane) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->pennylane) (2024.2.0)\nDownloading PennyLane-0.41.1-py3-none-any.whl (2.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading autoray-0.7.1-py3-none-any.whl (930 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m930.8/930.8 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pennylane_lightning-0.41.1-cp311-cp311-manylinux_2_28_x86_64.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading rustworkx-0.16.0-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\nDownloading diastatic_malt-2.15.2-py3-none-any.whl (167 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\nDownloading scipy_openblas32-0.3.29.0.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.6 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m102.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: appdirs, tomlkit, scipy-openblas32, autoray, diastatic-malt, rustworkx, pennylane-lightning, pennylane\nSuccessfully installed appdirs-1.4.4 autoray-0.7.1 diastatic-malt-2.15.2 pennylane-0.41.1 pennylane-lightning-0.41.1 rustworkx-0.16.0 scipy-openblas32-0.3.29.0.0 tomlkit-0.13.2\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\nSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\nCollecting torch_geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.11.18)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2025.3.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.1.6)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (7.0.0)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (3.0.9)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch_geometric) (4.67.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch_geometric) (1.20.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch_geometric) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torch_geometric) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch_geometric) (2025.4.26)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torch_geometric) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torch_geometric) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torch_geometric) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torch_geometric) (2024.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.6.1\nRequirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\nRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\nRequirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\nRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.0)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\nRequirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.0.1)\nRequirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\nRequirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.72.0rc1)\nRequirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\nRequirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\nRequirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\nRequirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\nRequirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\nRequirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (14.0.0)\nRequirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\nRequirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.1)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<2.1.0,>=1.26.0->tensorflow) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<2.1.0,>=1.26.0->tensorflow) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<2.1.0,>=1.26.0->tensorflow) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\nRequirement already satisfied: torchsummary in /usr/local/lib/python3.11/dist-packages (1.5.1)\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nimport matplotlib.pyplot as plt\nimport pennylane as qml\nfrom pennylane import numpy as pnp\nimport jax\nfrom jax import numpy as jnp\nimport optax\nwarnings.filterwarnings(\"ignore\")","metadata":{"id":"gSQMyKozA2r8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"3a03d208-101b-49e6-a490-01c834f52c62","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:52:13.510465Z","iopub.execute_input":"2025-05-18T16:52:13.510873Z","iopub.status.idle":"2025-05-18T16:52:17.834168Z","shell.execute_reply.started":"2025-05-18T16:52:13.510824Z","shell.execute_reply":"2025-05-18T16:52:17.833382Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pennylane/capture/capture_operators.py:33: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.4.28. You have version 0.5.2 installed. Please downgrade JAX to <=0.4.28 to avoid runtime errors.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/housing/train.csv')\ndf_val = pd.read_csv('/kaggle/input/housing/val.csv')\ndf_test = pd.read_csv('/kaggle/input/housing/test.csv')","metadata":{"id":"rS5RR9suA85Q","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:52:17.835024Z","iopub.execute_input":"2025-05-18T16:52:17.835516Z","iopub.status.idle":"2025-05-18T16:52:17.870172Z","shell.execute_reply.started":"2025-05-18T16:52:17.835497Z","shell.execute_reply":"2025-05-18T16:52:17.869604Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder, StandardScaler\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline","metadata":{"id":"VVrfxzqoBxOp","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:52:17.871569Z","iopub.execute_input":"2025-05-18T16:52:17.871850Z","iopub.status.idle":"2025-05-18T16:52:17.959023Z","shell.execute_reply.started":"2025-05-18T16:52:17.871832Z","shell.execute_reply":"2025-05-18T16:52:17.958514Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"features_numerical = df_train.select_dtypes(exclude=['object', 'bool']).copy()\nnumerical_cols = features_numerical.columns.tolist()\n\nnumerical_cols.remove('price')\n\nfeatures_categorical = df_train.select_dtypes(include=['object', 'bool']).copy()\ncategorical_cols = features_categorical.columns.tolist()\n\ncategorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\nnumerical_transformer = StandardScaler()\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('cat', categorical_transformer, categorical_cols),\n        ('num', numerical_transformer, numerical_cols)\n    ],\n    remainder='passthrough'\n)\n\ny_train = df_train['price'].copy()\ny_val = df_val['price'].copy()\n\ndf_train = df_train.drop(['price'], axis = 1)\ndf_val = df_val.drop(['price'], axis = 1)\n\ny_train.to_numpy()\ny_val.to_numpy()\n\nX_train = preprocessor.fit_transform(df_train)\nX_val = preprocessor.transform(df_val)\nX_test = preprocessor.transform(df_test)\n","metadata":{"id":"9_xjSHZ7Bzf7","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:52:17.959605Z","iopub.execute_input":"2025-05-18T16:52:17.959844Z","iopub.status.idle":"2025-05-18T16:52:18.009800Z","shell.execute_reply.started":"2025-05-18T16:52:17.959826Z","shell.execute_reply":"2025-05-18T16:52:18.009207Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Quantum","metadata":{"id":"h0tzycOxB4NP"}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pennylane as qml\nfrom pennylane import numpy as pnp\nimport jax\nfrom jax import numpy as jnp\nimport optax\nimport torch\nimport torch.nn as nn\nimport pennylane as qml\nimport random\n","metadata":{"id":"ERnNu8_d-UyD","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T18:11:58.768245Z","iopub.execute_input":"2025-05-18T18:11:58.768518Z","iopub.status.idle":"2025-05-18T18:11:58.772759Z","shell.execute_reply.started":"2025-05-18T18:11:58.768498Z","shell.execute_reply":"2025-05-18T18:11:58.771981Z"}},"outputs":[],"execution_count":79},{"cell_type":"code","source":"import os\n#from Uwb_dataset import import_from_files\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv1D, MaxPooling1D, GlobalMaxPooling1D, LSTM, Bidirectional\nimport tensorflow as tf\n# Loads and Processes the data that will be used in QCNN and Hierarchical Classifier Training\nimport numpy as np\n#import tensorflow as tf\nfrom sklearn.decomposition import PCA\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import layers, losses\nimport matplotlib.pyplot as plt\nimport pennylane as qml\nfrom pennylane import numpy as np\nimport autograd.numpy as anp\nfrom pennylane.templates.embeddings import AmplitudeEmbedding, AngleEmbedding\nfrom pennylane.templates.state_preparations import MottonenStatePreparation\nfrom pennylane.templates import RandomLayers\nfrom sklearn.preprocessing import normalize\nimport torch\ndevice = (\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"id":"CsKN0vYYRq7x","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T18:12:00.568707Z","iopub.execute_input":"2025-05-18T18:12:00.569290Z","iopub.status.idle":"2025-05-18T18:12:00.574736Z","shell.execute_reply.started":"2025-05-18T18:12:00.569270Z","shell.execute_reply":"2025-05-18T18:12:00.574031Z"}},"outputs":[],"execution_count":80},{"cell_type":"code","source":"scaler_y = StandardScaler()\ny_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\ny_val_scaled = scaler_y.transform(y_val.values.reshape(-1, 1))\n\nX_train_torch = torch.tensor(X_train, dtype = torch.float32).to(device)\nX_val_torch = torch.tensor(X_val, dtype = torch.float32).to(device)\nX_test_torch = torch.tensor(X_test, dtype = torch.float32).to(device)\ny_train_torch = torch.tensor(y_train_scaled, dtype = torch.float32).to(device)\ny_val_torch = torch.tensor(y_val_scaled, dtype = torch.float32).to(device)","metadata":{"id":"dXsoOaYjRvxQ","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T18:12:03.152353Z","iopub.execute_input":"2025-05-18T18:12:03.152585Z","iopub.status.idle":"2025-05-18T18:12:03.160138Z","shell.execute_reply.started":"2025-05-18T18:12:03.152569Z","shell.execute_reply":"2025-05-18T18:12:03.159450Z"}},"outputs":[],"execution_count":81},{"cell_type":"code","source":"def set_seed(seed):\n    torch.manual_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False\n\nset_seed(69)","metadata":{"id":"OBceHoby2-cT","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T18:12:05.393718Z","iopub.execute_input":"2025-05-18T18:12:05.394355Z","iopub.status.idle":"2025-05-18T18:12:05.399663Z","shell.execute_reply.started":"2025-05-18T18:12:05.394332Z","shell.execute_reply":"2025-05-18T18:12:05.398965Z"}},"outputs":[],"execution_count":82},{"cell_type":"code","source":"# import pennylane as qml\n\n# def U_4(params, wires): # 3 params 2 qubit\n#     qml.RZ(-np.pi / 2, wires = wires[1])\n#     qml.CNOT(wires = [wires[1], wires[0]]) # (source, target)\n#     qml.RZ(params[0], wires = wires[0])\n#     qml.RY(params[1], wires = wires[1])\n#     qml.CNOT(wires = [wires[0], wires[1]])\n#     qml.RZ(params[2], wires = wires[1])\n#     qml.CNOT(wires = [wires[1], wires[0]])\n#     qml.RZ(np.pi / 2, wires = wires[0])\n    \n# def conv_layer1(U, params, Uname): \n#     if Uname == 'U_4': # parameter 3\n#         U(params[0:3], wires=[0, 1])\n#         U(params[3:6], wires=[2, 3])\n#         U(params[6:9], wires=[4, 5])\n#         U(params[9:12], wires=[6, 7])\n#         U(params[12:15], wires=[8, 9])\n        \n#         U(params[15:18], wires=[1, 2])\n#         U(params[18:21], wires=[3, 4])\n#         U(params[21:24], wires=[5, 6])\n#         U(params[24:27], wires=[7, 8])\n#         U(params[27:30], wires=[9, 0])\n        \n# def U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires): # 15 params, Convolutional Circuit 10\n#     qml.U3(*weights_0, wires=wires[0])\n#     qml.U3(*weights_1, wires=wires[1])\n#     qml.CNOT(wires=[wires[0], wires[1]])\n#     qml.RY(weights_2, wires=wires[0])\n#     qml.RZ(weights_3, wires=wires[1])\n#     qml.CNOT(wires=[wires[1], wires[0]])\n#     qml.RY(weights_4, wires=wires[0])\n#     qml.CNOT(wires=[wires[0], wires[1]])\n#     qml.U3(*weights_5, wires=wires[0])\n#     qml.U3(*weights_6, wires=wires[1])\n    \n# # Unitary Ansatz for Pooling Layer\n# def Pooling_ansatz1(weights_0, weights_1, wires): #2 params\n#     qml.CRZ(weights_0, wires=[wires[0], wires[1]])\n#     qml.PauliX(wires=wires[0])\n#     qml.CRX(weights_1, wires=[wires[0], wires[1]])\n    \n    \n# n_qubits = 10\n# dev = qml.device(\"default.qubit\", wires=n_qubits)\n# @qml.qnode(dev, interface = \"torch\")\n# def qnode(inputs, weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, weights_7, weights_8): # , weights_9, weights_10, weights_11, weights_12, weights_13, weights_14, weights_15, weights_16, weights_17\n#     qml.AngleEmbedding(inputs, wires=range(n_qubits))\n#     #qml.AmplitudeEmbedding(inputs, wires=range(n_qubits), normalize=True)\n#     #qml.BasicEntanglerLayers(weights, wires=range(n_qubits))\n   \n#     # QCNN\n#     #--------------------------------------------------------- Convolutional Layer1 ---------------------------------------------------------#    \n#     U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires=[0, 1])\n#     U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires=[2, 3])\n#     U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires=[4, 5])\n#     U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires=[6, 7])\n#     U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires=[8, 9])\n    \n#     U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires=[1, 2])\n#     U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires=[3, 4])\n#     U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires=[5, 6])\n#     # U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires=[7, 0])\n#     U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires=[7, 8])\n#     U_SU4(weights_0, weights_1, weights_2, weights_3, weights_4, weights_5, weights_6, wires=[9, 0])\n\n#     #--------------------------------------------------------- Pooling Layer1 ---------------------------------------------------------#\n#     ## Pooling Circuit  Block 2 weights_7, weights_8\n#     Pooling_ansatz1(weights_7, weights_8, wires=[0,1])\n#     Pooling_ansatz1(weights_7, weights_8, wires=[2,3])\n#     Pooling_ansatz1(weights_7, weights_8, wires=[4,5])\n#     Pooling_ansatz1(weights_7, weights_8, wires=[6,7])\n#     Pooling_ansatz1(weights_7, weights_8, wires=[8,9])\n\n#     result = [qml.expval(qml.PauliZ(wires=i)) for i in range(n_qubits)]\n#     return result","metadata":{"id":"NEua2o1mRy67","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:52:33.535952Z","iopub.execute_input":"2025-05-18T16:52:33.536187Z","iopub.status.idle":"2025-05-18T16:52:33.552179Z","shell.execute_reply.started":"2025-05-18T16:52:33.536173Z","shell.execute_reply":"2025-05-18T16:52:33.551578Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# weight_shapes = {\n#     \"weights_0\": 3,\n#     \"weights_1\": 3,\n#     \"weights_2\": 1,\n#     \"weights_3\": 1,\n#     \"weights_4\": 1,\n#     \"weights_5\": 3,\n#     \"weights_6\": 3,\n#     \"weights_7\": 1,\n#     \"weights_8\": 1,    \n# }\n\n# qlayer = qml.qnn.TorchLayer(qnode, weight_shapes)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T16:52:33.552850Z","iopub.execute_input":"2025-05-18T16:52:33.553039Z","iopub.status.idle":"2025-05-18T16:52:33.584293Z","shell.execute_reply.started":"2025-05-18T16:52:33.553025Z","shell.execute_reply":"2025-05-18T16:52:33.583828Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"n_qubits = 6\ndev = qml.device(\"default.qubit\", wires = n_qubits)\n\n@qml.qnode(dev, interface = \"torch\")\ndef quantum_circuit(inputs, weights):\n    qml.AngleEmbedding(inputs, wires = range(n_qubits))\n    qml.BasicEntanglerLayers(weights, wires = range(n_qubits))\n    # qml.StronglyEntanglingLayers(weights, wires = range(n_qubits))\n    return [qml.expval(qml.PauliZ(i)) for i in range(n_qubits)]\n\nweight_shapes = {\"weights\": (3, n_qubits)}\n\nqlayer = qml.qnn.TorchLayer(quantum_circuit, weight_shapes)\n","metadata":{"id":"7CPq5-7b3KOC","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T18:12:09.421723Z","iopub.execute_input":"2025-05-18T18:12:09.421987Z","iopub.status.idle":"2025-05-18T18:12:09.428013Z","shell.execute_reply.started":"2025-05-18T18:12:09.421968Z","shell.execute_reply":"2025-05-18T18:12:09.427445Z"}},"outputs":[],"execution_count":83},{"cell_type":"code","source":"class HybridQNN(nn.Module):\n    def __init__(self, in_dim, hidden_dim, out_dim):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Linear(in_dim, hidden_dim),\n            qlayer, # Sử dụng qlayer đã tạo\n            nn.Linear(hidden_dim, out_dim)\n        )\n        # self.layers = []\n        # in_features = in_dim\n        # for hdim in hidden_dim:\n        #     self.layers.append(nn.Linear(in_features, hdim))\n        #     self.layers.append(nn.ReLU())\n        #     self.layers.append(nn.Dropout(0.3))\n        #     in_features = hdim\n        # self.layers.append(nn.Linear(in_features, out_dim))\n        # self.model = nn.Sequential(*self.layers)\n    def forward(self, x):\n        # x = self.classical1(x)\n        # # x = self.quantum(x)\n        # x = self.classical2(x)\n        # return x\n\n        return self.model(x)\n\nmodel = HybridQNN(in_dim = X_train_torch.shape[1], hidden_dim = n_qubits, out_dim = 1).to(device)","metadata":{"id":"jypunGUC5JVd","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T18:13:42.435870Z","iopub.execute_input":"2025-05-18T18:13:42.436528Z","iopub.status.idle":"2025-05-18T18:13:42.442574Z","shell.execute_reply.started":"2025-05-18T18:13:42.436505Z","shell.execute_reply":"2025-05-18T18:13:42.442048Z"}},"outputs":[],"execution_count":92},{"cell_type":"code","source":"def init_weights(m):\n    if isinstance(m, nn.Linear):\n        nn.init.xavier_uniform_(m.weight)\n        if m.bias is not None:\n            nn.init.constant_(m.bias, 0)","metadata":{"id":"z9duO-fu6StO","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T18:13:44.938477Z","iopub.execute_input":"2025-05-18T18:13:44.939024Z","iopub.status.idle":"2025-05-18T18:13:44.942481Z","shell.execute_reply.started":"2025-05-18T18:13:44.939001Z","shell.execute_reply":"2025-05-18T18:13:44.941929Z"}},"outputs":[],"execution_count":93},{"cell_type":"code","source":"model.apply(init_weights)\ncriterion = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=1)\n","metadata":{"id":"QIWA_Lys6hUC","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T18:13:46.962147Z","iopub.execute_input":"2025-05-18T18:13:46.962672Z","iopub.status.idle":"2025-05-18T18:13:46.967341Z","shell.execute_reply.started":"2025-05-18T18:13:46.962637Z","shell.execute_reply":"2025-05-18T18:13:46.966625Z"}},"outputs":[],"execution_count":94},{"cell_type":"code","source":"from torchsummary import summary as summary\n\nsummary(model, (27,)) # (model, input_size)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3sX6lY3C6uL0","outputId":"67fa83db-783f-4fb7-9ffc-f22ee6f8be0c","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T18:13:49.074863Z","iopub.execute_input":"2025-05-18T18:13:49.075437Z","iopub.status.idle":"2025-05-18T18:13:49.110806Z","shell.execute_reply.started":"2025-05-18T18:13:49.075416Z","shell.execute_reply":"2025-05-18T18:13:49.110206Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Linear-1                    [-1, 6]             168\n        TorchLayer-2                    [-1, 6]               0\n            Linear-3                    [-1, 1]               7\n================================================================\nTotal params: 175\nTrainable params: 175\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.00\nParams size (MB): 0.00\nEstimated Total Size (MB): 0.00\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":95},{"cell_type":"code","source":"batch_size = 64\nbatches = 1945 // batch_size\n\ndata_loader = torch.utils.data.DataLoader(\n    list(zip(X_train, y_train)), batch_size= 64, shuffle=True, drop_last=False\n)\nval_data_loder = torch.utils.data.DataLoader(\n    list(zip(X_val, y_val)), batch_size=64, shuffle=True, drop_last=False\n)\nepochs = 300\ncount = 0\ntrain_losses = []\nval_losses = []\nbest_val_loss = float('inf')\nfor epoch in range(epochs):\n\n    running_loss = 0\n    running_loss_val = 0\n    model.train()\n    for i in range(0, len(X_train_torch), batch_size):\n        X_batch = X_train_torch[i:i + batch_size]\n        y_batch = y_train_torch[i:i + batch_size]\n        optimizer.zero_grad()\n\n        loss_evaluated = criterion(model(X_batch), y_batch)\n        loss_evaluated.backward()\n\n        optimizer.step()\n\n        #running_loss += loss_evaluated\n        running_loss += loss_evaluated.item() * len(X_batch)\n    avg_loss = running_loss / len(X_train_torch)\n    print(f\"loss in train set over epoch {epoch}\", avg_loss)\n    model.eval()\n    with torch.no_grad():\n        # y_pred_tr = model(X_train)\n        # predictions_tr = torch.argmax(y_pred_tr, axis=1).detach().numpy()\n        # correct_tr = [1 if p == p_true else 0 for p, p_true in zip(predictions_tr, y_train)]\n        # accuracy_tr = sum(correct_tr) / len(correct_tr)\n        # print(\"training_Accuracy : \", accuracy_tr)\n        val_pred = model(X_val_torch)\n        val_loss = criterion(val_pred, y_val_torch)\n    print(f\"loss in val set over epoch {epoch}\", val_loss.item())\n        # y_pred_val = model(X_val)\n        # predictions_val = torch.argmax(y_pred_val, axis=1).detach().numpy()\n        # correct_val = [1 if p == p_true else 0 for p, p_true in zip(predictions_val, y_val)]\n        # accuracy_val = sum(correct_val) / len(correct_val)\n        # print(\"Validation_Accuracy : \", accuracy_val)\n    #print(f\"Accuracy: {accuracy * 100}%\")\n    train_losses.append(avg_loss)\n    val_losses.append(val_loss.item())\n    scheduler.step()\n    print(f\"Learning rate after epoch {epoch+1}: {scheduler.get_last_lr()[0]}\")\n    if val_loss < best_val_loss:\n        best_val_loss = val_loss\n        best_model = model.state_dict()\n\n\n\n# model.eval()\n# with torch.no_grad():\n#     y_pred = model(X_test)\n#     predictions = torch.argmax(y_pred, axis=1).detach().numpy()\n# correct = [1 if p == p_true else 0 for p, p_true in zip(predictions, Y_test)]\n# accuracy = sum(correct) / len(correct)\n# print(f\"Accuracy: {accuracy * 100}%\")","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yYunRHIY64hP","outputId":"6c14ef40-ebdb-4744-8280-fe55a7b4ec8e","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T18:13:52.547618Z","iopub.execute_input":"2025-05-18T18:13:52.548201Z","iopub.status.idle":"2025-05-18T18:21:35.014201Z","shell.execute_reply.started":"2025-05-18T18:13:52.548180Z","shell.execute_reply":"2025-05-18T18:21:35.013547Z"}},"outputs":[{"name":"stdout","text":"loss in train set over epoch 0 0.9911756395374288\nloss in val set over epoch 0 0.9212707281112671\nLearning rate after epoch 1: 0.001\nloss in train set over epoch 1 0.9517636005553611\nloss in val set over epoch 1 0.8908469676971436\nLearning rate after epoch 2: 0.001\nloss in train set over epoch 2 0.9236346551262627\nloss in val set over epoch 2 0.8662493228912354\nLearning rate after epoch 3: 0.001\nloss in train set over epoch 3 0.8974678071421646\nloss in val set over epoch 3 0.8403849005699158\nLearning rate after epoch 4: 0.001\nloss in train set over epoch 4 0.867504536952335\nloss in val set over epoch 4 0.8080334663391113\nLearning rate after epoch 5: 0.001\nloss in train set over epoch 5 0.8305250045879334\nloss in val set over epoch 5 0.7664425373077393\nLearning rate after epoch 6: 0.001\nloss in train set over epoch 6 0.7859810106552045\nloss in val set over epoch 6 0.7171018123626709\nLearning rate after epoch 7: 0.001\nloss in train set over epoch 7 0.7367355364453824\nloss in val set over epoch 7 0.6656107306480408\nLearning rate after epoch 8: 0.001\nloss in train set over epoch 8 0.6878223634624236\nloss in val set over epoch 8 0.6176210045814514\nLearning rate after epoch 9: 0.001\nloss in train set over epoch 9 0.6427429582894921\nloss in val set over epoch 9 0.5753191709518433\nLearning rate after epoch 10: 0.001\nloss in train set over epoch 10 0.602164615181234\nloss in val set over epoch 10 0.5383079051971436\nLearning rate after epoch 11: 0.001\nloss in train set over epoch 11 0.5654886384243217\nloss in val set over epoch 11 0.5055721998214722\nLearning rate after epoch 12: 0.001\nloss in train set over epoch 12 0.5321463883689252\nloss in val set over epoch 12 0.4763660430908203\nLearning rate after epoch 13: 0.001\nloss in train set over epoch 13 0.5018747402034259\nloss in val set over epoch 13 0.45031335949897766\nLearning rate after epoch 14: 0.001\nloss in train set over epoch 14 0.4744695787564648\nloss in val set over epoch 14 0.4272126257419586\nLearning rate after epoch 15: 0.001\nloss in train set over epoch 15 0.44960819611512604\nloss in val set over epoch 15 0.4068908393383026\nLearning rate after epoch 16: 0.001\nloss in train set over epoch 16 0.4269395561328584\nloss in val set over epoch 16 0.38915011286735535\nLearning rate after epoch 17: 0.001\nloss in train set over epoch 17 0.406207278853517\nloss in val set over epoch 17 0.3737495541572571\nLearning rate after epoch 18: 0.001\nloss in train set over epoch 18 0.3872590773516265\nloss in val set over epoch 18 0.3604144752025604\nLearning rate after epoch 19: 0.001\nloss in train set over epoch 19 0.36999607889082253\nloss in val set over epoch 19 0.34886276721954346\nLearning rate after epoch 20: 0.001\nloss in train set over epoch 20 0.3543351325706835\nloss in val set over epoch 20 0.33882614970207214\nLearning rate after epoch 21: 0.001\nloss in train set over epoch 21 0.3401957715231839\nloss in val set over epoch 21 0.330061674118042\nLearning rate after epoch 22: 0.001\nloss in train set over epoch 22 0.3274967815391815\nloss in val set over epoch 22 0.3223605155944824\nLearning rate after epoch 23: 0.001\nloss in train set over epoch 23 0.3161500896003988\nloss in val set over epoch 23 0.3155538737773895\nLearning rate after epoch 24: 0.001\nloss in train set over epoch 24 0.30605310336483166\nloss in val set over epoch 24 0.3095128834247589\nLearning rate after epoch 25: 0.001\nloss in train set over epoch 25 0.29708668048706643\nloss in val set over epoch 25 0.30414071679115295\nLearning rate after epoch 26: 0.001\nloss in train set over epoch 26 0.289120905626096\nloss in val set over epoch 26 0.29936274886131287\nLearning rate after epoch 27: 0.001\nloss in train set over epoch 27 0.282025162419807\nloss in val set over epoch 27 0.2951189875602722\nLearning rate after epoch 28: 0.001\nloss in train set over epoch 28 0.2756778171712145\nloss in val set over epoch 28 0.2913593351840973\nLearning rate after epoch 29: 0.001\nloss in train set over epoch 29 0.2699723077004244\nloss in val set over epoch 29 0.28804048895835876\nLearning rate after epoch 30: 0.001\nloss in train set over epoch 30 0.2648189861394446\nloss in val set over epoch 30 0.28512436151504517\nLearning rate after epoch 31: 0.001\nloss in train set over epoch 31 0.2601445012503234\nloss in val set over epoch 31 0.2825760245323181\nLearning rate after epoch 32: 0.001\nloss in train set over epoch 32 0.25588945896582616\nloss in val set over epoch 32 0.2803628742694855\nLearning rate after epoch 33: 0.001\nloss in train set over epoch 33 0.2520055654499402\nloss in val set over epoch 33 0.27845340967178345\nLearning rate after epoch 34: 0.001\nloss in train set over epoch 34 0.24845286856733434\nloss in val set over epoch 34 0.276817262172699\nLearning rate after epoch 35: 0.001\nloss in train set over epoch 35 0.24519741398050118\nloss in val set over epoch 35 0.2754250168800354\nLearning rate after epoch 36: 0.001\nloss in train set over epoch 36 0.2422097705706839\nloss in val set over epoch 36 0.27424827218055725\nLearning rate after epoch 37: 0.001\nloss in train set over epoch 37 0.23946350801420088\nloss in val set over epoch 37 0.2732606828212738\nLearning rate after epoch 38: 0.001\nloss in train set over epoch 38 0.23693476457981952\nloss in val set over epoch 38 0.27243733406066895\nLearning rate after epoch 39: 0.001\nloss in train set over epoch 39 0.23460168285357616\nloss in val set over epoch 39 0.27175581455230713\nLearning rate after epoch 40: 0.001\nloss in train set over epoch 40 0.23244405296896908\nloss in val set over epoch 40 0.2711954116821289\nLearning rate after epoch 41: 0.001\nloss in train set over epoch 41 0.2304433047924679\nloss in val set over epoch 41 0.2707380950450897\nLearning rate after epoch 42: 0.001\nloss in train set over epoch 42 0.22858234610226588\nloss in val set over epoch 42 0.27036741375923157\nLearning rate after epoch 43: 0.001\nloss in train set over epoch 43 0.22684548500264518\nloss in val set over epoch 43 0.27006909251213074\nLearning rate after epoch 44: 0.001\nloss in train set over epoch 44 0.225218432582436\nloss in val set over epoch 44 0.2698304057121277\nLearning rate after epoch 45: 0.001\nloss in train set over epoch 45 0.22368817137875102\nloss in val set over epoch 45 0.26964035630226135\nLearning rate after epoch 46: 0.001\nloss in train set over epoch 46 0.22224309901805034\nloss in val set over epoch 46 0.2694893777370453\nLearning rate after epoch 47: 0.001\nloss in train set over epoch 47 0.22087283684539305\nloss in val set over epoch 47 0.2693687975406647\nLearning rate after epoch 48: 0.001\nloss in train set over epoch 48 0.21956828788191005\nloss in val set over epoch 48 0.2692715525627136\nLearning rate after epoch 49: 0.001\nloss in train set over epoch 49 0.21832156926010446\nloss in val set over epoch 49 0.2691909074783325\nLearning rate after epoch 50: 0.001\nloss in train set over epoch 50 0.217125912466515\nloss in val set over epoch 50 0.2691217064857483\nLearning rate after epoch 51: 0.001\nloss in train set over epoch 51 0.2159756740138586\nloss in val set over epoch 51 0.26905912160873413\nLearning rate after epoch 52: 0.001\nloss in train set over epoch 52 0.21486604931575168\nloss in val set over epoch 52 0.26899874210357666\nLearning rate after epoch 53: 0.001\nloss in train set over epoch 53 0.21379300924377148\nloss in val set over epoch 53 0.26893728971481323\nLearning rate after epoch 54: 0.001\nloss in train set over epoch 54 0.21275321222209687\nloss in val set over epoch 54 0.26887133717536926\nLearning rate after epoch 55: 0.001\nloss in train set over epoch 55 0.21174370020551364\nloss in val set over epoch 55 0.2687981426715851\nLearning rate after epoch 56: 0.001\nloss in train set over epoch 56 0.21076192968455562\nloss in val set over epoch 56 0.268714964389801\nLearning rate after epoch 57: 0.001\nloss in train set over epoch 57 0.20980556350594007\nloss in val set over epoch 57 0.2686193883419037\nLearning rate after epoch 58: 0.001\nloss in train set over epoch 58 0.2088726357889666\nloss in val set over epoch 58 0.26850953698158264\nLearning rate after epoch 59: 0.001\nloss in train set over epoch 59 0.2079613028501177\nloss in val set over epoch 59 0.2683833837509155\nLearning rate after epoch 60: 0.001\nloss in train set over epoch 60 0.20706994739626858\nloss in val set over epoch 60 0.2682396471500397\nLearning rate after epoch 61: 0.001\nloss in train set over epoch 61 0.20619724484826116\nloss in val set over epoch 61 0.2680770754814148\nLearning rate after epoch 62: 0.001\nloss in train set over epoch 62 0.20534210437980593\nloss in val set over epoch 62 0.26789596676826477\nLearning rate after epoch 63: 0.001\nloss in train set over epoch 63 0.20450380948637936\nloss in val set over epoch 63 0.267696350812912\nLearning rate after epoch 64: 0.001\nloss in train set over epoch 64 0.20368188979693122\nloss in val set over epoch 64 0.2674797773361206\nLearning rate after epoch 65: 0.001\nloss in train set over epoch 65 0.20287615713546087\nloss in val set over epoch 65 0.2672485113143921\nLearning rate after epoch 66: 0.001\nloss in train set over epoch 66 0.2020867569587531\nloss in val set over epoch 66 0.2670056223869324\nLearning rate after epoch 67: 0.001\nloss in train set over epoch 67 0.20131406560348666\nloss in val set over epoch 67 0.266754686832428\nLearning rate after epoch 68: 0.001\nloss in train set over epoch 68 0.20055861473083497\nloss in val set over epoch 68 0.2665000259876251\nLearning rate after epoch 69: 0.001\nloss in train set over epoch 69 0.19982104072380802\nloss in val set over epoch 69 0.2662457525730133\nLearning rate after epoch 70: 0.001\nloss in train set over epoch 70 0.19910206850666007\nloss in val set over epoch 70 0.26599615812301636\nLearning rate after epoch 71: 0.001\nloss in train set over epoch 71 0.19840222042446579\nloss in val set over epoch 71 0.2657548487186432\nLearning rate after epoch 72: 0.001\nloss in train set over epoch 72 0.19772205990200484\nloss in val set over epoch 72 0.26552489399909973\nLearning rate after epoch 73: 0.001\nloss in train set over epoch 73 0.1970619019934941\nloss in val set over epoch 73 0.2653088867664337\nLearning rate after epoch 74: 0.001\nloss in train set over epoch 74 0.1964219110560601\nloss in val set over epoch 74 0.2651081085205078\nLearning rate after epoch 75: 0.001\nloss in train set over epoch 75 0.1958020489749075\nloss in val set over epoch 75 0.26492375135421753\nLearning rate after epoch 76: 0.001\nloss in train set over epoch 76 0.1952021064366044\nloss in val set over epoch 76 0.26475590467453003\nLearning rate after epoch 77: 0.001\nloss in train set over epoch 77 0.19462167789206714\nloss in val set over epoch 77 0.2646045684814453\nLearning rate after epoch 78: 0.001\nloss in train set over epoch 78 0.19406032335482404\nloss in val set over epoch 78 0.264469176530838\nLearning rate after epoch 79: 0.001\nloss in train set over epoch 79 0.19351741381966364\nloss in val set over epoch 79 0.2643490135669708\nLearning rate after epoch 80: 0.001\nloss in train set over epoch 80 0.19299231707130424\nloss in val set over epoch 80 0.26424336433410645\nLearning rate after epoch 81: 0.001\nloss in train set over epoch 81 0.19248431599998228\nloss in val set over epoch 81 0.26415136456489563\nLearning rate after epoch 82: 0.001\nloss in train set over epoch 82 0.19199265919644912\nloss in val set over epoch 82 0.26407238841056824\nLearning rate after epoch 83: 0.001\nloss in train set over epoch 83 0.19151662642514491\nloss in val set over epoch 83 0.2640054523944855\nLearning rate after epoch 84: 0.001\nloss in train set over epoch 84 0.19105541540601872\nloss in val set over epoch 84 0.26395002007484436\nLearning rate after epoch 85: 0.001\nloss in train set over epoch 85 0.19060834963401363\nloss in val set over epoch 85 0.26390540599823\nLearning rate after epoch 86: 0.001\nloss in train set over epoch 86 0.19017464941448908\nloss in val set over epoch 86 0.2638711929321289\nLearning rate after epoch 87: 0.001\nloss in train set over epoch 87 0.18975363956778704\nloss in val set over epoch 87 0.2638466954231262\nLearning rate after epoch 88: 0.001\nloss in train set over epoch 88 0.1893446319054209\nloss in val set over epoch 88 0.26383161544799805\nLearning rate after epoch 89: 0.001\nloss in train set over epoch 89 0.18894692957401277\nloss in val set over epoch 89 0.26382556557655334\nLearning rate after epoch 90: 0.001\nloss in train set over epoch 90 0.18855993556945674\nloss in val set over epoch 90 0.2638281285762787\nLearning rate after epoch 91: 0.001\nloss in train set over epoch 91 0.18818296657583095\nloss in val set over epoch 91 0.26383885741233826\nLearning rate after epoch 92: 0.001\nloss in train set over epoch 92 0.18781548487956237\nloss in val set over epoch 92 0.2638574540615082\nLearning rate after epoch 93: 0.001\nloss in train set over epoch 93 0.1874568884430937\nloss in val set over epoch 93 0.26388370990753174\nLearning rate after epoch 94: 0.001\nloss in train set over epoch 94 0.187106633638355\nloss in val set over epoch 94 0.2639169991016388\nLearning rate after epoch 95: 0.001\nloss in train set over epoch 95 0.1867641956073766\nloss in val set over epoch 95 0.263957142829895\nLearning rate after epoch 96: 0.001\nloss in train set over epoch 96 0.18642906667640705\nloss in val set over epoch 96 0.2640039920806885\nLearning rate after epoch 97: 0.001\nloss in train set over epoch 97 0.18610074896279216\nloss in val set over epoch 97 0.2640567719936371\nLearning rate after epoch 98: 0.001\nloss in train set over epoch 98 0.18577877218741684\nloss in val set over epoch 98 0.2641155421733856\nLearning rate after epoch 99: 0.001\nloss in train set over epoch 99 0.18546274718098285\nloss in val set over epoch 99 0.26417970657348633\nLearning rate after epoch 100: 0.001\nloss in train set over epoch 100 0.18515218127815766\nloss in val set over epoch 100 0.26424914598464966\nLearning rate after epoch 101: 0.001\nloss in train set over epoch 101 0.18484668484230582\nloss in val set over epoch 101 0.26432332396507263\nLearning rate after epoch 102: 0.001\nloss in train set over epoch 102 0.1845458898492215\nloss in val set over epoch 102 0.2644021809101105\nLearning rate after epoch 103: 0.001\nloss in train set over epoch 103 0.18424942770776528\nloss in val set over epoch 103 0.2644849121570587\nLearning rate after epoch 104: 0.001\nloss in train set over epoch 104 0.18395690377849538\nloss in val set over epoch 104 0.26457157731056213\nLearning rate after epoch 105: 0.001\nloss in train set over epoch 105 0.18366804798648412\nloss in val set over epoch 105 0.2646616995334625\nLearning rate after epoch 106: 0.001\nloss in train set over epoch 106 0.18338253488117748\nloss in val set over epoch 106 0.2647551894187927\nLearning rate after epoch 107: 0.001\nloss in train set over epoch 107 0.18310002769633246\nloss in val set over epoch 107 0.26485148072242737\nLearning rate after epoch 108: 0.001\nloss in train set over epoch 108 0.18282030538911992\nloss in val set over epoch 108 0.26495030522346497\nLearning rate after epoch 109: 0.001\nloss in train set over epoch 109 0.18254311603414983\nloss in val set over epoch 109 0.26505133509635925\nLearning rate after epoch 110: 0.001\nloss in train set over epoch 110 0.18226817875411025\nloss in val set over epoch 110 0.26515454053878784\nLearning rate after epoch 111: 0.001\nloss in train set over epoch 111 0.18199528049687186\nloss in val set over epoch 111 0.26525935530662537\nLearning rate after epoch 112: 0.001\nloss in train set over epoch 112 0.181724248385981\nloss in val set over epoch 112 0.26536548137664795\nLearning rate after epoch 113: 0.001\nloss in train set over epoch 113 0.18145493931666132\nloss in val set over epoch 113 0.26547273993492126\nLearning rate after epoch 114: 0.001\nloss in train set over epoch 114 0.18118715112344158\nloss in val set over epoch 114 0.26558080315589905\nLearning rate after epoch 115: 0.001\nloss in train set over epoch 115 0.1809207788240021\nloss in val set over epoch 115 0.26568928360939026\nLearning rate after epoch 116: 0.001\nloss in train set over epoch 116 0.18065569021554717\nloss in val set over epoch 116 0.26579827070236206\nLearning rate after epoch 117: 0.001\nloss in train set over epoch 117 0.180391856522364\nloss in val set over epoch 117 0.26590728759765625\nLearning rate after epoch 118: 0.001\nloss in train set over epoch 118 0.18012915970733662\nloss in val set over epoch 118 0.26601582765579224\nLearning rate after epoch 119: 0.001\nloss in train set over epoch 119 0.17986762478449658\nloss in val set over epoch 119 0.2661239504814148\nLearning rate after epoch 120: 0.001\nloss in train set over epoch 120 0.1796071896209815\nloss in val set over epoch 120 0.26623132824897766\nLearning rate after epoch 121: 0.001\nloss in train set over epoch 121 0.17934791022830268\nloss in val set over epoch 121 0.2663375735282898\nLearning rate after epoch 122: 0.001\nloss in train set over epoch 122 0.17908981517531877\nloss in val set over epoch 122 0.2664424777030945\nLearning rate after epoch 123: 0.001\nloss in train set over epoch 123 0.17883297054044386\nloss in val set over epoch 123 0.26654577255249023\nLearning rate after epoch 124: 0.001\nloss in train set over epoch 124 0.17857746887942513\nloss in val set over epoch 124 0.2666472792625427\nLearning rate after epoch 125: 0.001\nloss in train set over epoch 125 0.17832336821868672\nloss in val set over epoch 125 0.26674684882164\nLearning rate after epoch 126: 0.001\nloss in train set over epoch 126 0.17807085476528403\nloss in val set over epoch 126 0.2668442130088806\nLearning rate after epoch 127: 0.001\nloss in train set over epoch 127 0.1778200305979172\nloss in val set over epoch 127 0.26693880558013916\nLearning rate after epoch 128: 0.001\nloss in train set over epoch 128 0.17757105523179306\nloss in val set over epoch 128 0.26703080534935\nLearning rate after epoch 129: 0.001\nloss in train set over epoch 129 0.17732407781642628\nloss in val set over epoch 129 0.26712000370025635\nLearning rate after epoch 130: 0.001\nloss in train set over epoch 130 0.17707929462577507\nloss in val set over epoch 130 0.2672058939933777\nLearning rate after epoch 131: 0.001\nloss in train set over epoch 131 0.17683682417195376\nloss in val set over epoch 131 0.2672886252403259\nLearning rate after epoch 132: 0.001\nloss in train set over epoch 132 0.176596916809793\nloss in val set over epoch 132 0.2673676908016205\nLearning rate after epoch 133: 0.001\nloss in train set over epoch 133 0.17635967234259706\nloss in val set over epoch 133 0.2674430012702942\nLearning rate after epoch 134: 0.001\nloss in train set over epoch 134 0.17612530397572063\nloss in val set over epoch 134 0.2675143778324127\nLearning rate after epoch 135: 0.001\nloss in train set over epoch 135 0.17589387134445358\nloss in val set over epoch 135 0.2675818204879761\nLearning rate after epoch 136: 0.001\nloss in train set over epoch 136 0.17566560896779088\nloss in val set over epoch 136 0.267645001411438\nLearning rate after epoch 137: 0.001\nloss in train set over epoch 137 0.17544057141692596\nloss in val set over epoch 137 0.2677040100097656\nLearning rate after epoch 138: 0.001\nloss in train set over epoch 138 0.17521887878985515\nloss in val set over epoch 138 0.26775845885276794\nLearning rate after epoch 139: 0.001\nloss in train set over epoch 139 0.17500063326487506\nloss in val set over epoch 139 0.2678084373474121\nLearning rate after epoch 140: 0.001\nloss in train set over epoch 140 0.17478586002456498\nloss in val set over epoch 140 0.26785358786582947\nLearning rate after epoch 141: 0.001\nloss in train set over epoch 141 0.1745746242586322\nloss in val set over epoch 141 0.26789405941963196\nLearning rate after epoch 142: 0.001\nloss in train set over epoch 142 0.17436694879764764\nloss in val set over epoch 142 0.2679298222064972\nLearning rate after epoch 143: 0.001\nloss in train set over epoch 143 0.17416282685373008\nloss in val set over epoch 143 0.2679605782032013\nLearning rate after epoch 144: 0.001\nloss in train set over epoch 144 0.173962292734026\nloss in val set over epoch 144 0.2679864764213562\nLearning rate after epoch 145: 0.001\nloss in train set over epoch 145 0.17376523204818176\nloss in val set over epoch 145 0.2680074870586395\nLearning rate after epoch 146: 0.001\nloss in train set over epoch 146 0.17357168243599427\nloss in val set over epoch 146 0.2680235207080841\nLearning rate after epoch 147: 0.001\nloss in train set over epoch 147 0.17338154925785212\nloss in val set over epoch 147 0.26803457736968994\nLearning rate after epoch 148: 0.001\nloss in train set over epoch 148 0.17319475162611522\nloss in val set over epoch 148 0.26804107427597046\nLearning rate after epoch 149: 0.001\nloss in train set over epoch 149 0.17301126885536705\nloss in val set over epoch 149 0.2680424451828003\nLearning rate after epoch 150: 0.001\nloss in train set over epoch 150 0.172830961962592\nloss in val set over epoch 150 0.26803913712501526\nLearning rate after epoch 151: 0.001\nloss in train set over epoch 151 0.17265377787820477\nloss in val set over epoch 151 0.2680310904979706\nLearning rate after epoch 152: 0.001\nloss in train set over epoch 152 0.17247960187475603\nloss in val set over epoch 152 0.2680183947086334\nLearning rate after epoch 153: 0.001\nloss in train set over epoch 153 0.17230837663065804\nloss in val set over epoch 153 0.26800137758255005\nLearning rate after epoch 154: 0.001\nloss in train set over epoch 154 0.17213998430798783\nloss in val set over epoch 154 0.26797980070114136\nLearning rate after epoch 155: 0.001\nloss in train set over epoch 155 0.17197431567242336\nloss in val set over epoch 155 0.26795387268066406\nLearning rate after epoch 156: 0.001\nloss in train set over epoch 156 0.17181130963303437\nloss in val set over epoch 156 0.26792383193969727\nLearning rate after epoch 157: 0.001\nloss in train set over epoch 157 0.17165086170548338\nloss in val set over epoch 157 0.26788944005966187\nLearning rate after epoch 158: 0.001\nloss in train set over epoch 158 0.17149288698762732\nloss in val set over epoch 158 0.267851322889328\nLearning rate after epoch 159: 0.001\nloss in train set over epoch 159 0.17133730204062475\nloss in val set over epoch 159 0.26780959963798523\nLearning rate after epoch 160: 0.001\nloss in train set over epoch 160 0.1711840289953742\nloss in val set over epoch 160 0.2677639126777649\nLearning rate after epoch 161: 0.001\nloss in train set over epoch 161 0.17103297401669706\nloss in val set over epoch 161 0.2677147388458252\nLearning rate after epoch 162: 0.001\nloss in train set over epoch 162 0.17088409307530117\nloss in val set over epoch 162 0.2676621675491333\nLearning rate after epoch 163: 0.001\nloss in train set over epoch 163 0.1707372863832047\nloss in val set over epoch 163 0.26760634779930115\nLearning rate after epoch 164: 0.001\nloss in train set over epoch 164 0.1705925218013994\nloss in val set over epoch 164 0.2675475776195526\nLearning rate after epoch 165: 0.001\nloss in train set over epoch 165 0.1704496861040439\nloss in val set over epoch 165 0.26748573780059814\nLearning rate after epoch 166: 0.001\nloss in train set over epoch 166 0.17030877421938057\nloss in val set over epoch 166 0.2674209475517273\nLearning rate after epoch 167: 0.001\nloss in train set over epoch 167 0.17016970193478012\nloss in val set over epoch 167 0.26735350489616394\nLearning rate after epoch 168: 0.001\nloss in train set over epoch 168 0.17003241361413332\nloss in val set over epoch 168 0.26728355884552\nLearning rate after epoch 169: 0.001\nloss in train set over epoch 169 0.16989683261414112\nloss in val set over epoch 169 0.26721134781837463\nLearning rate after epoch 170: 0.001\nloss in train set over epoch 170 0.1697629714992788\nloss in val set over epoch 170 0.2671366333961487\nLearning rate after epoch 171: 0.001\nloss in train set over epoch 171 0.16963074903714934\nloss in val set over epoch 171 0.267059862613678\nLearning rate after epoch 172: 0.001\nloss in train set over epoch 172 0.1695001180573417\nloss in val set over epoch 172 0.26698124408721924\nLearning rate after epoch 173: 0.001\nloss in train set over epoch 173 0.16937105258816618\nloss in val set over epoch 173 0.2669006288051605\nLearning rate after epoch 174: 0.001\nloss in train set over epoch 174 0.16924350222615778\nloss in val set over epoch 174 0.26681840419769287\nLearning rate after epoch 175: 0.001\nloss in train set over epoch 175 0.16911743720730044\nloss in val set over epoch 175 0.26673436164855957\nLearning rate after epoch 176: 0.001\nloss in train set over epoch 176 0.16899279349107668\nloss in val set over epoch 176 0.2666490375995636\nLearning rate after epoch 177: 0.001\nloss in train set over epoch 177 0.1688695933794301\nloss in val set over epoch 177 0.2665623128414154\nLearning rate after epoch 178: 0.001\nloss in train set over epoch 178 0.1687477535867446\nloss in val set over epoch 178 0.26647427678108215\nLearning rate after epoch 179: 0.001\nloss in train set over epoch 179 0.16862725838444226\nloss in val set over epoch 179 0.26638516783714294\nLearning rate after epoch 180: 0.001\nloss in train set over epoch 180 0.16850805662591536\nloss in val set over epoch 180 0.2662951350212097\nLearning rate after epoch 181: 0.001\nloss in train set over epoch 181 0.16839016370264606\nloss in val set over epoch 181 0.2662040591239929\nLearning rate after epoch 182: 0.001\nloss in train set over epoch 182 0.16827352816157598\nloss in val set over epoch 182 0.2661123275756836\nLearning rate after epoch 183: 0.001\nloss in train set over epoch 183 0.16815810750566595\nloss in val set over epoch 183 0.26601994037628174\nLearning rate after epoch 184: 0.001\nloss in train set over epoch 184 0.16804388896358657\nloss in val set over epoch 184 0.2659268081188202\nLearning rate after epoch 185: 0.001\nloss in train set over epoch 185 0.1679308343286073\nloss in val set over epoch 185 0.2658332586288452\nLearning rate after epoch 186: 0.001\nloss in train set over epoch 186 0.1678189366136541\nloss in val set over epoch 186 0.26573944091796875\nLearning rate after epoch 187: 0.001\nloss in train set over epoch 187 0.16770815529829433\nloss in val set over epoch 187 0.26564526557922363\nLearning rate after epoch 188: 0.001\nloss in train set over epoch 188 0.16759848384746856\nloss in val set over epoch 188 0.26555103063583374\nLearning rate after epoch 189: 0.001\nloss in train set over epoch 189 0.16748988652903501\nloss in val set over epoch 189 0.26545658707618713\nLearning rate after epoch 190: 0.001\nloss in train set over epoch 190 0.16738237466634392\nloss in val set over epoch 190 0.26536211371421814\nLearning rate after epoch 191: 0.001\nloss in train set over epoch 191 0.16727587618987175\nloss in val set over epoch 191 0.2652676999568939\nLearning rate after epoch 192: 0.001\nloss in train set over epoch 192 0.16717039468509065\nloss in val set over epoch 192 0.2651735246181488\nLearning rate after epoch 193: 0.001\nloss in train set over epoch 193 0.16706592076695057\nloss in val set over epoch 193 0.26507946848869324\nLearning rate after epoch 194: 0.001\nloss in train set over epoch 194 0.1669624109730929\nloss in val set over epoch 194 0.26498547196388245\nLearning rate after epoch 195: 0.001\nloss in train set over epoch 195 0.1668598774849296\nloss in val set over epoch 195 0.26489201188087463\nLearning rate after epoch 196: 0.001\nloss in train set over epoch 196 0.16675828506063986\nloss in val set over epoch 196 0.2647991180419922\nLearning rate after epoch 197: 0.001\nloss in train set over epoch 197 0.1666576043192709\nloss in val set over epoch 197 0.26470649242401123\nLearning rate after epoch 198: 0.001\nloss in train set over epoch 198 0.16655787345223072\nloss in val set over epoch 198 0.264614462852478\nLearning rate after epoch 199: 0.001\nloss in train set over epoch 199 0.166459027989971\nloss in val set over epoch 199 0.26452305912971497\nLearning rate after epoch 200: 0.001\nloss in train set over epoch 200 0.16636104753054198\nloss in val set over epoch 200 0.26443228125572205\nLearning rate after epoch 201: 0.001\nloss in train set over epoch 201 0.1662639526674251\nloss in val set over epoch 201 0.2643422782421112\nLearning rate after epoch 202: 0.001\nloss in train set over epoch 202 0.16616771621078943\nloss in val set over epoch 202 0.2642526924610138\nLearning rate after epoch 203: 0.001\nloss in train set over epoch 203 0.1660722987434245\nloss in val set over epoch 203 0.26416414976119995\nLearning rate after epoch 204: 0.001\nloss in train set over epoch 204 0.1659777332164328\nloss in val set over epoch 204 0.264076292514801\nLearning rate after epoch 205: 0.001\nloss in train set over epoch 205 0.16588399923552585\nloss in val set over epoch 205 0.2639894187450409\nLearning rate after epoch 206: 0.001\nloss in train set over epoch 206 0.1657910481669909\nloss in val set over epoch 206 0.26390331983566284\nLearning rate after epoch 207: 0.001\nloss in train set over epoch 207 0.16569888251606174\nloss in val set over epoch 207 0.2638181746006012\nLearning rate after epoch 208: 0.001\nloss in train set over epoch 208 0.1656075283540245\nloss in val set over epoch 208 0.26373401284217834\nLearning rate after epoch 209: 0.001\nloss in train set over epoch 209 0.1655169232568888\nloss in val set over epoch 209 0.2636508047580719\nLearning rate after epoch 210: 0.001\nloss in train set over epoch 210 0.1654271117366065\nloss in val set over epoch 210 0.2635684907436371\nLearning rate after epoch 211: 0.001\nloss in train set over epoch 211 0.16533803134620342\nloss in val set over epoch 211 0.26348745822906494\nLearning rate after epoch 212: 0.001\nloss in train set over epoch 212 0.1652497077585799\nloss in val set over epoch 212 0.2634073793888092\nLearning rate after epoch 213: 0.001\nloss in train set over epoch 213 0.16516211457301536\nloss in val set over epoch 213 0.263328492641449\nLearning rate after epoch 214: 0.001\nloss in train set over epoch 214 0.1650752641394696\nloss in val set over epoch 214 0.26325052976608276\nLearning rate after epoch 215: 0.001\nloss in train set over epoch 215 0.16498912004394825\nloss in val set over epoch 215 0.2631738483905792\nLearning rate after epoch 216: 0.001\nloss in train set over epoch 216 0.16490366721674227\nloss in val set over epoch 216 0.26309826970100403\nLearning rate after epoch 217: 0.001\nloss in train set over epoch 217 0.16481897460924017\nloss in val set over epoch 217 0.26302388310432434\nLearning rate after epoch 218: 0.001\nloss in train set over epoch 218 0.16473496774628107\nloss in val set over epoch 218 0.2629505693912506\nLearning rate after epoch 219: 0.001\nloss in train set over epoch 219 0.16465161751505647\nloss in val set over epoch 219 0.26287874579429626\nLearning rate after epoch 220: 0.001\nloss in train set over epoch 220 0.16456899334961467\nloss in val set over epoch 220 0.26280781626701355\nLearning rate after epoch 221: 0.001\nloss in train set over epoch 221 0.16448704110779308\nloss in val set over epoch 221 0.26273834705352783\nLearning rate after epoch 222: 0.001\nloss in train set over epoch 222 0.16440577140810558\nloss in val set over epoch 222 0.2626698315143585\nLearning rate after epoch 223: 0.001\nloss in train set over epoch 223 0.1643251628219928\nloss in val set over epoch 223 0.26260292530059814\nLearning rate after epoch 224: 0.001\nloss in train set over epoch 224 0.1642452091744749\nloss in val set over epoch 224 0.2625369131565094\nLearning rate after epoch 225: 0.001\nloss in train set over epoch 225 0.16416593681264352\nloss in val set over epoch 225 0.2624724209308624\nLearning rate after epoch 226: 0.001\nloss in train set over epoch 226 0.16408732238496176\nloss in val set over epoch 226 0.26240915060043335\nLearning rate after epoch 227: 0.001\nloss in train set over epoch 227 0.16400934250924765\nloss in val set over epoch 227 0.2623472213745117\nLearning rate after epoch 228: 0.001\nloss in train set over epoch 228 0.16393203736883816\nloss in val set over epoch 228 0.2622862160205841\nLearning rate after epoch 229: 0.001\nloss in train set over epoch 229 0.16385536514854676\nloss in val set over epoch 229 0.26222696900367737\nLearning rate after epoch 230: 0.001\nloss in train set over epoch 230 0.16377932986287655\nloss in val set over epoch 230 0.262168824672699\nLearning rate after epoch 231: 0.001\nloss in train set over epoch 231 0.16370393844527267\nloss in val set over epoch 231 0.262112021446228\nLearning rate after epoch 232: 0.001\nloss in train set over epoch 232 0.16362918389333858\nloss in val set over epoch 232 0.2620563805103302\nLearning rate after epoch 233: 0.001\nloss in train set over epoch 233 0.16355509058522075\nloss in val set over epoch 233 0.26200219988822937\nLearning rate after epoch 234: 0.001\nloss in train set over epoch 234 0.16348159709289325\nloss in val set over epoch 234 0.2619493007659912\nLearning rate after epoch 235: 0.001\nloss in train set over epoch 235 0.16340873514165608\nloss in val set over epoch 235 0.26189762353897095\nLearning rate after epoch 236: 0.001\nloss in train set over epoch 236 0.1633365287878826\nloss in val set over epoch 236 0.2618473172187805\nLearning rate after epoch 237: 0.001\nloss in train set over epoch 237 0.1632649201507127\nloss in val set over epoch 237 0.26179808378219604\nLearning rate after epoch 238: 0.001\nloss in train set over epoch 238 0.16319394817235844\nloss in val set over epoch 238 0.2617504298686981\nLearning rate after epoch 239: 0.001\nloss in train set over epoch 239 0.16312359681779132\nloss in val set over epoch 239 0.2617039084434509\nLearning rate after epoch 240: 0.001\nloss in train set over epoch 240 0.1630538723615877\nloss in val set over epoch 240 0.26165878772735596\nLearning rate after epoch 241: 0.001\nloss in train set over epoch 241 0.16298476128161413\nloss in val set over epoch 241 0.26161494851112366\nLearning rate after epoch 242: 0.001\nloss in train set over epoch 242 0.1629162820108752\nloss in val set over epoch 242 0.2615722417831421\nLearning rate after epoch 243: 0.001\nloss in train set over epoch 243 0.16284842384658313\nloss in val set over epoch 243 0.26153093576431274\nLearning rate after epoch 244: 0.001\nloss in train set over epoch 244 0.16278117717384985\nloss in val set over epoch 244 0.26149091124534607\nLearning rate after epoch 245: 0.001\nloss in train set over epoch 245 0.16271454064429267\nloss in val set over epoch 245 0.26145198941230774\nLearning rate after epoch 246: 0.001\nloss in train set over epoch 246 0.1626485352344562\nloss in val set over epoch 246 0.2614143490791321\nLearning rate after epoch 247: 0.001\nloss in train set over epoch 247 0.16258314066497095\nloss in val set over epoch 247 0.2613779306411743\nLearning rate after epoch 248: 0.001\nloss in train set over epoch 248 0.16251834858505768\nloss in val set over epoch 248 0.2613427937030792\nLearning rate after epoch 249: 0.001\nloss in train set over epoch 249 0.16245418816115373\nloss in val set over epoch 249 0.2613087594509125\nLearning rate after epoch 250: 0.001\nloss in train set over epoch 250 0.1623906281199737\nloss in val set over epoch 250 0.26127609610557556\nLearning rate after epoch 251: 0.001\nloss in train set over epoch 251 0.16232768203727996\nloss in val set over epoch 251 0.26124441623687744\nLearning rate after epoch 252: 0.001\nloss in train set over epoch 252 0.16226536207916192\nloss in val set over epoch 252 0.26121416687965393\nLearning rate after epoch 253: 0.001\nloss in train set over epoch 253 0.16220364477150237\nloss in val set over epoch 253 0.26118502020835876\nLearning rate after epoch 254: 0.001\nloss in train set over epoch 254 0.16214253908564316\nloss in val set over epoch 254 0.2611568570137024\nLearning rate after epoch 255: 0.001\nloss in train set over epoch 255 0.16208202874905653\nloss in val set over epoch 255 0.2611299455165863\nLearning rate after epoch 256: 0.001\nloss in train set over epoch 256 0.16202215444306176\nloss in val set over epoch 256 0.261104017496109\nLearning rate after epoch 257: 0.001\nloss in train set over epoch 257 0.16196290011730782\nloss in val set over epoch 257 0.26107925176620483\nLearning rate after epoch 258: 0.001\nloss in train set over epoch 258 0.1619042098981862\nloss in val set over epoch 258 0.261055588722229\nLearning rate after epoch 259: 0.001\nloss in train set over epoch 259 0.16184615170281466\nloss in val set over epoch 259 0.2610330879688263\nLearning rate after epoch 260: 0.001\nloss in train set over epoch 260 0.1617887314763351\nloss in val set over epoch 260 0.26101139187812805\nLearning rate after epoch 261: 0.001\nloss in train set over epoch 261 0.1617318779843019\nloss in val set over epoch 261 0.26099085807800293\nLearning rate after epoch 262: 0.001\nloss in train set over epoch 262 0.1616756398987341\nloss in val set over epoch 262 0.2609712481498718\nLearning rate after epoch 263: 0.001\nloss in train set over epoch 263 0.16161997706693979\nloss in val set over epoch 263 0.26095256209373474\nLearning rate after epoch 264: 0.001\nloss in train set over epoch 264 0.16156494463470725\nloss in val set over epoch 264 0.26093509793281555\nLearning rate after epoch 265: 0.001\nloss in train set over epoch 265 0.16151051902832286\nloss in val set over epoch 265 0.260918527841568\nLearning rate after epoch 266: 0.001\nloss in train set over epoch 266 0.16145663066817434\nloss in val set over epoch 266 0.2609027922153473\nLearning rate after epoch 267: 0.001\nloss in train set over epoch 267 0.16140339462646788\nloss in val set over epoch 267 0.260888010263443\nLearning rate after epoch 268: 0.001\nloss in train set over epoch 268 0.16135071493819317\nloss in val set over epoch 268 0.26087385416030884\nLearning rate after epoch 269: 0.001\nloss in train set over epoch 269 0.1612986452245467\nloss in val set over epoch 269 0.2608608305454254\nLearning rate after epoch 270: 0.001\nloss in train set over epoch 270 0.16124715883964744\nloss in val set over epoch 270 0.26084864139556885\nLearning rate after epoch 271: 0.001\nloss in train set over epoch 271 0.1611962372892007\nloss in val set over epoch 271 0.2608373165130615\nLearning rate after epoch 272: 0.001\nloss in train set over epoch 272 0.1611459166654278\nloss in val set over epoch 272 0.26082679629325867\nLearning rate after epoch 273: 0.001\nloss in train set over epoch 273 0.16109615606483274\nloss in val set over epoch 273 0.26081714034080505\nLearning rate after epoch 274: 0.001\nloss in train set over epoch 274 0.16104698649255658\nloss in val set over epoch 274 0.26080799102783203\nLearning rate after epoch 275: 0.001\nloss in train set over epoch 275 0.16099839544541425\nloss in val set over epoch 275 0.260799765586853\nLearning rate after epoch 276: 0.001\nloss in train set over epoch 276 0.1609503074063127\nloss in val set over epoch 276 0.26079219579696655\nLearning rate after epoch 277: 0.001\nloss in train set over epoch 277 0.16090285027241646\nloss in val set over epoch 277 0.2607852816581726\nLearning rate after epoch 278: 0.001\nloss in train set over epoch 278 0.16085590976829087\nloss in val set over epoch 278 0.2607792317867279\nLearning rate after epoch 279: 0.001\nloss in train set over epoch 279 0.16080953730868802\nloss in val set over epoch 279 0.2607736885547638\nLearning rate after epoch 280: 0.001\nloss in train set over epoch 280 0.160763708676348\nloss in val set over epoch 280 0.26076892018318176\nLearning rate after epoch 281: 0.001\nloss in train set over epoch 281 0.16071843581135292\nloss in val set over epoch 281 0.2607644498348236\nLearning rate after epoch 282: 0.001\nloss in train set over epoch 282 0.16067368592348688\nloss in val set over epoch 282 0.2607608735561371\nLearning rate after epoch 283: 0.001\nloss in train set over epoch 283 0.1606294689034435\nloss in val set over epoch 283 0.26075780391693115\nLearning rate after epoch 284: 0.001\nloss in train set over epoch 284 0.16058576552910792\nloss in val set over epoch 284 0.2607552707195282\nLearning rate after epoch 285: 0.001\nloss in train set over epoch 285 0.1605426163170822\nloss in val set over epoch 285 0.2607533037662506\nLearning rate after epoch 286: 0.001\nloss in train set over epoch 286 0.16049994857728023\nloss in val set over epoch 286 0.2607519328594208\nLearning rate after epoch 287: 0.001\nloss in train set over epoch 287 0.16045781957766084\nloss in val set over epoch 287 0.26075103878974915\nLearning rate after epoch 288: 0.001\nloss in train set over epoch 288 0.1604161794970152\nloss in val set over epoch 288 0.26075053215026855\nLearning rate after epoch 289: 0.001\nloss in train set over epoch 289 0.1603750383869235\nloss in val set over epoch 289 0.26075050234794617\nLearning rate after epoch 290: 0.001\nloss in train set over epoch 290 0.16033439732379348\nloss in val set over epoch 290 0.26075103878974915\nLearning rate after epoch 291: 0.001\nloss in train set over epoch 291 0.16029424834757047\nloss in val set over epoch 291 0.2607519328594208\nLearning rate after epoch 292: 0.001\nloss in train set over epoch 292 0.16025455353882134\nloss in val set over epoch 292 0.260753333568573\nLearning rate after epoch 293: 0.001\nloss in train set over epoch 293 0.16021533642912278\nloss in val set over epoch 293 0.26075509190559387\nLearning rate after epoch 294: 0.001\nloss in train set over epoch 294 0.1601766173246587\nloss in val set over epoch 294 0.26075705885887146\nLearning rate after epoch 295: 0.001\nloss in train set over epoch 295 0.16013833074076317\nloss in val set over epoch 295 0.2607596516609192\nLearning rate after epoch 296: 0.001\nloss in train set over epoch 296 0.16010049650096037\nloss in val set over epoch 296 0.26076242327690125\nLearning rate after epoch 297: 0.001\nloss in train set over epoch 297 0.16006311831330272\nloss in val set over epoch 297 0.26076552271842957\nLearning rate after epoch 298: 0.001\nloss in train set over epoch 298 0.16002616760127036\nloss in val set over epoch 298 0.26076894998550415\nLearning rate after epoch 299: 0.001\nloss in train set over epoch 299 0.1599896661381795\nloss in val set over epoch 299 0.26077261567115784\nLearning rate after epoch 300: 0.001\n","output_type":"stream"}],"execution_count":96},{"cell_type":"code","source":"model.load_state_dict(best_model)\nmodel.eval()\nwith torch.no_grad():\n    y_test_pred_scaled = model(X_test_torch)\n    y_test_pred = scaler_y.inverse_transform(y_test_pred_scaled.cpu().numpy())","metadata":{"id":"kl-C4RNb-dwx","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T18:24:22.457597Z","iopub.execute_input":"2025-05-18T18:24:22.458117Z","iopub.status.idle":"2025-05-18T18:24:22.489187Z","shell.execute_reply.started":"2025-05-18T18:24:22.458094Z","shell.execute_reply":"2025-05-18T18:24:22.488464Z"}},"outputs":[],"execution_count":97},{"cell_type":"code","source":"y_test_pred[:10], y_test_pred_scaled[:10], y_val_torch[:10]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2M1lCgj9_A5V","outputId":"9ccf9e61-af0f-41a9-8573-1c7ddd2cd079","trusted":true,"execution":{"iopub.status.busy":"2025-05-18T18:24:25.909152Z","iopub.execute_input":"2025-05-18T18:24:25.909615Z","iopub.status.idle":"2025-05-18T18:24:25.917779Z","shell.execute_reply.started":"2025-05-18T18:24:25.909592Z","shell.execute_reply":"2025-05-18T18:24:25.917109Z"}},"outputs":[{"execution_count":98,"output_type":"execute_result","data":{"text/plain":"(array([[13.170453 ],\n        [ 7.861731 ],\n        [26.640753 ],\n        [ 3.3612034],\n        [ 9.958742 ],\n        [12.81683  ],\n        [19.45771  ],\n        [27.440052 ],\n        [33.34973  ],\n        [14.5256195]], dtype=float32),\n tensor([[-0.0330],\n         [-0.5541],\n         [ 1.2894],\n         [-0.9960],\n         [-0.3483],\n         [-0.0677],\n         [ 0.5843],\n         [ 1.3679],\n         [ 1.9480],\n         [ 0.1001]], device='cuda:0'),\n tensor([[-1.0118],\n         [-0.4473],\n         [ 0.0681],\n         [ 0.6375],\n         [ 2.0610],\n         [ 1.4719],\n         [-1.0167],\n         [-0.9332],\n         [-0.4424],\n         [ 0.8338]], device='cuda:0'))"},"metadata":{}}],"execution_count":98},{"cell_type":"code","source":"mlp_submit = pd.DataFrame({\n    'Id': df_test.index,\n    'TARGET': y_test_pred.flatten()\n})\nmlp_submit.to_csv('quantum.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-18T18:24:29.353239Z","iopub.execute_input":"2025-05-18T18:24:29.353472Z","iopub.status.idle":"2025-05-18T18:24:29.360204Z","shell.execute_reply.started":"2025-05-18T18:24:29.353457Z","shell.execute_reply":"2025-05-18T18:24:29.359453Z"}},"outputs":[],"execution_count":99}]}