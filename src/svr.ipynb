{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024bec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4636ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('data/train.csv')\n",
    "df_val = pd.read_csv('data/val.csv')\n",
    "df_test = pd.read_csv('data/test.csv')\n",
    "df = pd.concat([df_train, df_val], axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5c7f01",
   "metadata": {},
   "source": [
    "# Visualize bar chart with each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84e6fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df.drop(columns=['price', 'area', 'street_in_front_of_house', 'width'])\n",
    "total_features = features.columns.to_list()\n",
    "total_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6d0825",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_unique_fields = {}\n",
    "for i in total_features:\n",
    "    feature_unique_fields[i] = features[i].unique().tolist()\n",
    "\n",
    "len_features = len(feature_unique_fields)\n",
    "for i in range(len_features):\n",
    "    list(feature_unique_fields.values())[i].sort()\n",
    "feature_unique_value = {}\n",
    "for feature in total_features:\n",
    "    # print(\"Feature: \\n\", feature)\n",
    "    feature_len = len(feature_unique_fields[feature])\n",
    "    # print(\"Len: \", feature_len)\n",
    "    feature_value = feature_unique_fields[feature]\n",
    "    # print(feature_value)\n",
    "    feature_unique_value[feature] = [sum(df[df[feature] == feature_value[i]].price) / df[feature].value_counts()[feature_value[i]] for i in range(feature_len)]\n",
    "    \n",
    "# print(feature_unique_value)\n",
    "feature_unique_fields\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933943ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualized_features = total_features\n",
    "name_of_features = ['floor_number',\n",
    " 'bedroom_number',\n",
    " 'is_dinning_room',\n",
    " 'is_kitchen',\n",
    " 'is_terrace',\n",
    " 'is_car_pack',\n",
    " 'type',\n",
    " 'direction',\n",
    " 'city',\n",
    " 'district']\n",
    "labels = ['Sá»‘ táº§ng', 'Sá»‘ phÃ²ng ngá»§', 'CÃ³ phÃ²ng Äƒn hay khÃ´ng', 'CÃ³ phÃ²ng báº¿p hay khÃ´ng', 'CÃ³ sÃ¢n thÆ°á»£ng hay khÃ´ng', \n",
    "'CÃ³ chá»— Ä‘á»ƒ xe hay khÃ´ng','Loáº¡i báº¥t Ä‘á»™ng sáº£n','ThÃ nh phá»‘', 'Quáº­n/Huyá»‡n']\n",
    "titles = ['Biá»ƒu Ä‘á»“ thá»ƒ hiá»‡n giÃ¡ nhÃ  trung bÃ¬nh theo sá»‘ táº§ng nhÃ ','Biá»ƒu Ä‘á»“ giÃ¡ nhÃ  trung bÃ¬nh theo sá»‘ phÃ²ng ngá»§', 'Biá»ƒu Ä‘á»“ giÃ¡ nhÃ  trung bÃ¬nh theo phÃ²ng Äƒn', \n",
    "'Biá»ƒu Ä‘á»“ giÃ¡ nhÃ  trung bÃ¬nh cÃ³ vÃ  khÃ´ng cÃ³ báº¿p', 'GiÃ¡ nhÃ  trung bÃ¬nh vá»›i sÃ¢n thÆ°á»£ng', 'GiÃ¡ nhÃ  trung bÃ¬nh vá»›i chá»— Ä‘á»ƒ xe', \n",
    "'Biá»ƒu Ä‘á»“ thá»ƒ hiá»‡n giÃ¡ nhÃ  trung bÃ¬nh theo loáº¡i báº¥t Ä‘á»™ng sáº£n', \n",
    "'Biá»ƒu Ä‘á»“ thá»ƒ hiá»‡n giÃ¡ nhÃ  trung bÃ¬nh theo thÃ nh phá»‘', 'Biá»ƒu Ä‘á»“ thá»ƒ hiá»‡n giÃ¡ nhÃ  trung bÃ¬nh theo quáº­n/huyá»‡n báº¥t Ä‘á»™ng sáº£n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ac6788",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "count = 0\n",
    "for feature in visualized_features:\n",
    "    N = len(feature_unique_value[feature])\n",
    "    ind = np.arange(N) \n",
    "    all_colors = list(plt.cm.colors.cnames.keys())\n",
    "    random.seed(100)\n",
    "    c = random.choices(all_colors, k=N) \n",
    "    text_value = {}\n",
    "    for i in ind:\n",
    "        text_value[i] = feature_unique_value[feature][i]\n",
    "        \n",
    "    fig = plt.subplots(figsize=(10, 7))\n",
    "    plt.bar(ind, feature_unique_value[feature], color=c)\n",
    "    \n",
    "    for key in text_value:\n",
    "        plt.text(key, text_value[key], float(round(text_value[key], 2)), \n",
    "                horizontalalignment='center', verticalalignment='bottom', \n",
    "                fontdict={'fontweight':500, 'size':12})\n",
    "    \n",
    "    # Decide whether to rotate labels based on number of categories and label length\n",
    "    max_label_length = max([len(str(label)) for label in feature_unique_fields[feature]])\n",
    "    available_width = 10  # Figure width in inches\n",
    "    \n",
    "    # Apply rotation if many values or long labels\n",
    "    if N > 5 or (N * max_label_length > 30):\n",
    "        plt.xticks(ind, list(feature_unique_fields[feature]), rotation=45, ha='right')\n",
    "    else:\n",
    "        plt.xticks(ind, list(feature_unique_fields[feature]))  # No rotation\n",
    "    \n",
    "    plt.xlabel(labels[count])\n",
    "    plt.ylabel(\"GiÃ¡ (tá»· Ä‘á»“ng)\")\n",
    "    plt.title(titles[count], fontsize=22)\n",
    "    plt.tight_layout()\n",
    "    count += 1\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb53377",
   "metadata": {},
   "source": [
    "# Preprocessing to be ready for predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50add25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a93a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_numerical = df.select_dtypes(exclude=['object', 'bool']).copy()\n",
    "numerical_cols = features_numerical.columns.tolist()\n",
    "\n",
    "numerical_cols.remove('price')\n",
    "numerical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4c4561",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_categorical = df.select_dtypes(include=['object', 'bool']).copy()\n",
    "categorical_cols = features_categorical.columns.tolist()\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a012ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "numerical_transformer = StandardScaler()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', categorical_transformer, categorical_cols),\n",
    "        ('num', numerical_transformer, numerical_cols)     \n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75fb59f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['price'].copy()\n",
    "y_val = df_val['price'].copy()\n",
    "\n",
    "df_train = df_train.drop(['price'], axis = 1)\n",
    "df_val = df_val.drop(['price'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a5e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_numpy()\n",
    "y_val.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b08ffd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195533c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocessor.fit_transform(df_train)\n",
    "X_val = preprocessor.transform(df_val)\n",
    "X_test = preprocessor.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5d83ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_evaluate(y_true, y_pred):\n",
    "    plt.plot(y_true, y_pred, 'b.')\n",
    "    x = [np.min(y_true), np.max(y_true)]\n",
    "    y = x\n",
    "    plt.plot(x, y, 'r')\n",
    "    plt.title('XGBoost')\n",
    "    plt.xlabel('Reality')\n",
    "    plt.ylabel('Predict')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b6b3db",
   "metadata": {},
   "source": [
    "# Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de5ccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "svr_model = SVR(kernel='poly', gamma=0.0975, C=5.1, epsilon=2.4798, coef0 = 2.3)\n",
    "svr_model.fit(X_train, y_train)\n",
    "y_pred_val = svr_model.predict(X_val)\n",
    "y_test_pred = svr_model.predict(X_test)\n",
    "svr_submit = pd.DataFrame({\n",
    "    'Id': df_test.index,\n",
    "    'TARGET': y_test_pred\n",
    "})\n",
    "svr_submit.to_csv('data/svr_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5573ff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Giáº£ sá»­ X_train, y_train, X_val, y_val Ä‘Ã£ Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a\n",
    "\n",
    "r2_scores = []\n",
    "C_range = range(1, 101)  # Tá»« 1 Ä‘áº¿n 99\n",
    "\n",
    "best_score = -float('inf')\n",
    "best_params = {}\n",
    "\n",
    "for C_value in C_range: \n",
    "    model = SVR(kernel='rbf', C=C_value)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_val = model.predict(X_val)\n",
    "    score = r2_score(y_val, y_pred_val)\n",
    "    print(f\"C = {C_value}, RÂ² = {score:.4f}\")\n",
    "    r2_scores.append(score)\n",
    "\n",
    "    if score > best_score:\n",
    "        best_score = score\n",
    "        best_params = {\n",
    "            'C': C_value\n",
    "        }\n",
    "\n",
    "print(\"\\nBest parameters with highest RÂ² score:\")\n",
    "print(f\"C = {best_params['C']}, RÂ² = {best_score:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(C_range, r2_scores)\n",
    "plt.title('Sá»± thay Ä‘á»•i RÂ² theo tham sá»‘ C')\n",
    "plt.xlabel('GiÃ¡ trá»‹ C')\n",
    "plt.ylabel('RÂ² Score')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ab9f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "C_range = range(1, 101)\n",
    "rmse_val_scores = []\n",
    "rmse_train_scores = []\n",
    "best_rmse = float('inf')\n",
    "best_params = {}\n",
    "\n",
    "for C_val in C_range:\n",
    "    model = SVR(kernel='rbf', C=C_val)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Dá»± Ä‘oÃ¡n trÃªn táº­p validation\n",
    "    y_val_pred = model.predict(X_val)\n",
    "    rmse_val = np.sqrt(mean_squared_error(y_val, y_val_pred))\n",
    "    rmse_val_scores.append(rmse_val)\n",
    "    \n",
    "    # Dá»± Ä‘oÃ¡n trÃªn táº­p train\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    rmse_train = np.sqrt(mean_squared_error(y_train, y_train_pred))\n",
    "    rmse_train_scores.append(rmse_train)\n",
    "\n",
    "    print(f\"C = {C_val}, RMSE Train = {rmse_train:.4f}, RMSE Val = {rmse_val:.4f}\")\n",
    "    \n",
    "    if rmse_val < best_rmse:\n",
    "        best_rmse = rmse_val\n",
    "        best_params = {'C': C_val}\n",
    "\n",
    "print(\"\\nBest Validation RMSE:\")\n",
    "print(f\"C = {best_params['C']}, RMSE = {best_rmse:.4f}\")\n",
    "\n",
    "# Váº½ biá»ƒu Ä‘á»“ RMSE\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(C_range, rmse_train_scores, label='Train', color='blue')\n",
    "plt.plot(C_range, rmse_val_scores, label='Validation', color='orange')\n",
    "plt.title('RMSE trÃªn táº­p Train vÃ  Validation theo tham sá»‘ C (SVR vá»›i kernel RBF)')\n",
    "plt.xlabel('GiÃ¡ trá»‹ C')\n",
    "plt.ylabel('RMSE')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3006c70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "epsilon_values = np.linspace(0.01, 5, 100)\n",
    "rmse_scores = []\n",
    "\n",
    "best_rmse = float('inf')\n",
    "best_params = {}\n",
    "\n",
    "for eps in epsilon_values:\n",
    "    model = SVR(kernel='rbf', epsilon=eps)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_params = {'epsilon': eps}\n",
    "\n",
    "print(f\"Best epsilon: {best_params['epsilon']:.4f} with RMSE = {best_rmse:.4f}\")\n",
    "\n",
    "# Váº½ biá»ƒu Ä‘á»“ RMSE theo epsilon\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epsilon_values, rmse_scores)\n",
    "plt.title('Äá»“ thá»‹ biá»ƒu diá»…n sá»± thay Ä‘á»•i RMSE theo tham sá»‘ epsilon vá»›i kernel rbf')\n",
    "plt.xlabel('GiÃ¡ trá»‹ epsilon')\n",
    "plt.ylabel('RMSE')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1331ef5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "gamma_values = np.linspace(0.001, 0.2, 100)\n",
    "rmse_scores = []\n",
    "\n",
    "best_rmse = float('inf')\n",
    "best_gamma = None\n",
    "\n",
    "for gamma in gamma_values:\n",
    "    model = SVR(kernel='rbf', gamma=gamma)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_gamma = gamma\n",
    "\n",
    "print(f\"Best gamma: {best_gamma:.4f} with RMSE = {best_rmse:.4f}\")\n",
    "\n",
    "# Váº½ biá»ƒu Ä‘á»“\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(gamma_values, rmse_scores)\n",
    "plt.title('Äá»“ thá»‹ biá»ƒu diá»…n sá»± thay Ä‘á»•i RMSE theo tham sá»‘ gamma vá»›i kernel rbf')\n",
    "plt.xlabel('GiÃ¡ trá»‹ gamma')\n",
    "plt.ylabel('RMSE')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f5a346",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "gamma_values = np.linspace(0.001, 1, 100)\n",
    "rmse_scores = []\n",
    "\n",
    "best_rmse = float('inf')\n",
    "best_gamma = None\n",
    "\n",
    "for gamma in gamma_values:\n",
    "    model = SVR(kernel='rbf', gamma=gamma, C = 51, epsilon = 2.1774)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_gamma = gamma\n",
    "\n",
    "print(f\"Best gamma: {best_gamma:.4f} with RMSE = {best_rmse:.4f}\")\n",
    "\n",
    "# Váº½ biá»ƒu Ä‘á»“\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(gamma_values, rmse_scores)\n",
    "plt.title('Sá»± thay Ä‘á»•i RMSE theo gamma')\n",
    "plt.xlabel('GiÃ¡ trá»‹ gamma')\n",
    "plt.ylabel('RMSE')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45ae0cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "gamma_values = np.linspace(1, 5, 10)\n",
    "rmse_scores = []\n",
    "\n",
    "best_rmse = float('inf')\n",
    "best_gamma = None\n",
    "\n",
    "for gamma in gamma_values:\n",
    "    model = SVR(kernel='poly', C = 5.1, epsilon = 2.4798, gamma=0.0975, coef0=2.3, degree=2)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_val)\n",
    "    rmse = np.sqrt(mean_squared_error(y_val, y_pred))\n",
    "    rmse_scores.append(rmse)\n",
    "\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_gamma = gamma\n",
    "\n",
    "print(f\"Best gamma: {best_gamma:.4f} with RMSE = {best_rmse:.4f}\")\n",
    "\n",
    "# Váº½ biá»ƒu Ä‘á»“\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(gamma_values, rmse_scores)\n",
    "plt.title('Äá»“ thá»‹ biá»ƒu diá»…n sá»± thay Ä‘á»•i RMSE theo tham sá»‘ gamma vá»›i kernel rbf')\n",
    "plt.xlabel('GiÃ¡ trá»‹ gamma')\n",
    "plt.ylabel('RMSE')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54551f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- Chuáº©n hÃ³a dá»¯ liá»‡u y ---\n",
    "scaler_y = StandardScaler()\n",
    "y_train_scaled = scaler_y.fit_transform(y_train.values.reshape(-1, 1))\n",
    "y_val_scaled = scaler_y.transform(y_val.values.reshape(-1, 1))\n",
    "\n",
    "# --- Chuyá»ƒn Ä‘á»•i sang tensor ---\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "y_train_tensor = torch.tensor(y_train_scaled, dtype=torch.float32)\n",
    "y_val_tensor = torch.tensor(y_val_scaled, dtype=torch.float32)\n",
    "\n",
    "# --- Äá»‹nh nghÄ©a lá»›p mÃ´ hÃ¬nh MLP ---\n",
    "class FlexibleMLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_sizes):\n",
    "        super(FlexibleMLP, self).__init__()\n",
    "        layers = []\n",
    "        in_features = input_dim\n",
    "        for hidden_size in hidden_sizes:\n",
    "            layers.append(nn.Linear(in_features, hidden_size))\n",
    "            layers.append(nn.ReLU())\n",
    "            layers.append(nn.Dropout(0.3))\n",
    "            in_features = hidden_size\n",
    "        layers.append(nn.Linear(in_features, 1))  # Táº§ng Ä‘áº§u ra\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "# --- HÃ m huáº¥n luyá»‡n mÃ´ hÃ¬nh vÃ  tráº£ vá» RMSE ---\n",
    "def train_and_evaluate(hidden_sizes):\n",
    "    model = FlexibleMLP(X_train_tensor.shape[1], hidden_sizes)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.005, momentum=0.9)\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 20\n",
    "    patience_counter = 0\n",
    "    batch_size = 64\n",
    "    epochs = 200\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        for i in range(0, len(X_train_tensor), batch_size):\n",
    "            X_batch = X_train_tensor[i:i + batch_size]\n",
    "            y_batch = y_train_tensor[i:i + batch_size]\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = criterion(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            val_pred = model(X_val_tensor)\n",
    "            val_loss = criterion(val_pred, y_val_tensor)\n",
    "\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            patience_counter = 0\n",
    "            best_model = model.state_dict()\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            break\n",
    "\n",
    "    # Load best model\n",
    "    model.load_state_dict(best_model)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        y_val_pred_scaled = model(X_val_tensor)\n",
    "        y_val_pred = scaler_y.inverse_transform(y_val_pred_scaled.numpy())\n",
    "        y_val_true = scaler_y.inverse_transform(y_val_tensor.numpy())\n",
    "        rmse = np.sqrt(mean_squared_error(y_val_true, y_val_pred))\n",
    "\n",
    "    return model, rmse\n",
    "\n",
    "# --- Cháº¡y tá»« 1 Ä‘áº¿n 5 táº§ng áº©n theo quy táº¯c 256/2^(n-1) ---\n",
    "results = []\n",
    "best_rmse = float('inf')\n",
    "best_model = None\n",
    "best_test_pred = None\n",
    "\n",
    "for n_layers in range(1, 6):\n",
    "    hidden_sizes = [int(256 / (2 ** i)) for i in range(n_layers)]\n",
    "    print(f\"\\nğŸ” Training MLP with {n_layers} hidden layer(s), sizes = {hidden_sizes}\")\n",
    "    model, rmse = train_and_evaluate(hidden_sizes)\n",
    "    print(f\"âœ… RMSE: {rmse:.4f}\")\n",
    "\n",
    "    results.append((n_layers, hidden_sizes, rmse))\n",
    "\n",
    "    if rmse < best_rmse:\n",
    "        best_rmse = rmse\n",
    "        best_model = model\n",
    "        with torch.no_grad():\n",
    "            y_test_pred_scaled = best_model(X_test_tensor)\n",
    "            y_test_pred = scaler_y.inverse_transform(y_test_pred_scaled.numpy())\n",
    "\n",
    "# --- Xuáº¥t káº¿t quáº£ dá»± Ä‘oÃ¡n tá»« mÃ´ hÃ¬nh tá»‘t nháº¥t ---\n",
    "mlp_submit = pd.DataFrame({\n",
    "    'Id': df_test.index,\n",
    "    'TARGET': y_test_pred.flatten()\n",
    "})\n",
    "mlp_submit.to_csv('data/mlp_model_pytorch_best.csv', index=False)\n",
    "\n",
    "# --- In tÃ³m táº¯t káº¿t quáº£ ---\n",
    "print(\"\\nğŸ“Š TÃ³m táº¯t RMSE theo sá»‘ táº§ng:\")\n",
    "for n_layers, sizes, rmse in results:\n",
    "    print(f\"{n_layers} táº§ng áº©n {sizes} â†’ RMSE: {rmse:.4f}\")\n",
    "\n",
    "print(f\"\\nğŸ† MÃ´ hÃ¬nh tá»‘t nháº¥t: {best_rmse:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
